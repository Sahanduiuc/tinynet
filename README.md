TinyNet is a tiny neural network developed and vectorized with NumPy, and designed in a modular fashion. The aim is to provide students with an understanding of basic building blocks of neural networks and their coordination.

Features:
- Batch, mini-batch and stochastic GD
- Layers:
  - Dense
  - Convolutional (2D)
  - Pooling (2D)
- Regularizers:
  - L2
  - Dropout
- Optimizers:
  - Momentum
  - Adam
- Batch normalization
- Gradient Checking

Notebooks:

[Example with sklearn dataset](https://nbviewer.jupyter.org/github/polakowo/tinynet/blob/master/examples/sklearn.ipynb)

![](examples/images/sklearn.png)

[Example with MNIST dataset](https://nbviewer.jupyter.org/github/polakowo/tinynet/blob/master/examples/mnist.ipynb)

![](examples/images/mnist.png)
