This code aims to help with understanding of the basic building blocks of neural networks. 

Features:
- Batch, mini-batch and stochastic GD
- Layers:
  - Dense
  - Convolutional (2D)
  - Pooling (2D)
- Regularizers:
  - L2
  - Dropout
- Optimizers:
  - Momentum
  - Adam
- Batch normalization
- Gradient Checking

Notebooks:

[Example with sklearn dataset](https://nbviewer.jupyter.org/github/polakowo/numpy-dnn/blob/master/examples/sklearn.ipynb)

![](examples/images/sklearn.png)

[Example with MNIST dataset](https://nbviewer.jupyter.org/github/polakowo/numpy-dnn/blob/master/examples/mnist.ipynb)

![](examples/images/mnist.png)
